{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KRqRVP4bxGJ",
        "outputId": "ffb1bb03-d74b-425f-bf26-057b2981b7fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Track_Deep_Learning'...\n",
            "remote: Enumerating objects: 17020, done.\u001b[K\n",
            "remote: Total 17020 (delta 0), reused 0 (delta 0), pack-reused 17020\u001b[K\n",
            "Receiving objects: 100% (17020/17020), 245.61 MiB | 14.67 MiB/s, done.\n",
            "Updating files: 100% (17017/17017), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Rishikesh-Jadhav/Track_Deep_Learning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWHO_QTWcUce",
        "outputId": "353a2e08-2a28-4841-99cb-3c09b7c4ebb3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  Track_Deep_Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Track_Deep_Learning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMQuon7VcVp2",
        "outputId": "be4f1840-110e-4503-a518-4493ff1629b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "driving_log.csv  IMG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Till now we have created the dataset from the simulator 3 laps front  and 3 laps reverse so the model doesnt become left turn bias as our track consists majorly of left turns"
      ],
      "metadata": {
        "id": "tJoYmllZcaMv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import random\n",
        "import os # module helpful for path inclusion instead of specifying string path\n",
        "import ntpath # to split path\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "nwWTErzvc85v"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = 'Track_Deep_Learning'\n",
        "columns = ['center','left','right','steering','throttle','reverse','speed']\n",
        "df = pd.read_csv(os.path.join(data_directory,'driving_log.csv'), names = columns)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "df.head(5) # column overflows and we need to see full path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "oPKlP7J9dw3a",
        "outputId": "3090b013-4e90-40af-b994-b68db1fd4a22"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-17b2f0ce6025>:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  pd.set_option('display.max_colwidth', -1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                     center  \\\n",
              "0  C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\center_2023_02_13_14_28_29_922.jpg   \n",
              "1  C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\center_2023_02_13_14_28_30_025.jpg   \n",
              "2  C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\center_2023_02_13_14_28_30_127.jpg   \n",
              "3  C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\center_2023_02_13_14_28_30_227.jpg   \n",
              "4  C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\center_2023_02_13_14_28_30_329.jpg   \n",
              "\n",
              "                                                                                                      left  \\\n",
              "0   C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\left_2023_02_13_14_28_29_922.jpg   \n",
              "1   C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\left_2023_02_13_14_28_30_025.jpg   \n",
              "2   C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\left_2023_02_13_14_28_30_127.jpg   \n",
              "3   C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\left_2023_02_13_14_28_30_227.jpg   \n",
              "4   C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\left_2023_02_13_14_28_30_329.jpg   \n",
              "\n",
              "                                                                                                      right  \\\n",
              "0   C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\right_2023_02_13_14_28_29_922.jpg   \n",
              "1   C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\right_2023_02_13_14_28_30_025.jpg   \n",
              "2   C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\right_2023_02_13_14_28_30_127.jpg   \n",
              "3   C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\right_2023_02_13_14_28_30_227.jpg   \n",
              "4   C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\right_2023_02_13_14_28_30_329.jpg   \n",
              "\n",
              "   steering  throttle  reverse     speed  \n",
              "0  0.0       0.0       0.0      0.000078  \n",
              "1  0.0       0.0       0.0      0.000081  \n",
              "2  0.0       0.0       0.0      0.000079  \n",
              "3  0.0       0.0       0.0      0.000078  \n",
              "4  0.0       0.0       0.0      0.000079  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a89f405-90f6-43de-9ceb-cfd2bda164a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>center</th>\n",
              "      <th>left</th>\n",
              "      <th>right</th>\n",
              "      <th>steering</th>\n",
              "      <th>throttle</th>\n",
              "      <th>reverse</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\center_2023_02_13_14_28_29_922.jpg</td>\n",
              "      <td>C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\left_2023_02_13_14_28_29_922.jpg</td>\n",
              "      <td>C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\right_2023_02_13_14_28_29_922.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\center_2023_02_13_14_28_30_025.jpg</td>\n",
              "      <td>C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\left_2023_02_13_14_28_30_025.jpg</td>\n",
              "      <td>C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\right_2023_02_13_14_28_30_025.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\center_2023_02_13_14_28_30_127.jpg</td>\n",
              "      <td>C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\left_2023_02_13_14_28_30_127.jpg</td>\n",
              "      <td>C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\right_2023_02_13_14_28_30_127.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\center_2023_02_13_14_28_30_227.jpg</td>\n",
              "      <td>C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\left_2023_02_13_14_28_30_227.jpg</td>\n",
              "      <td>C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\right_2023_02_13_14_28_30_227.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\center_2023_02_13_14_28_30_329.jpg</td>\n",
              "      <td>C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\left_2023_02_13_14_28_30_329.jpg</td>\n",
              "      <td>C:\\Users\\rishi\\OneDrive\\Desktop\\Autonomous_car_deep_learning\\data\\IMG\\right_2023_02_13_14_28_30_329.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000079</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a89f405-90f6-43de-9ceb-cfd2bda164a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a89f405-90f6-43de-9ceb-cfd2bda164a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a89f405-90f6-43de-9ceb-cfd2bda164a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we have to get rid of the path from the desktop and keep tail end of the path\n",
        "def path_leaf(path): # apply this to all of our data\n",
        "  head,tail = ntpath.split(path)\n",
        "  return tail\n",
        "\n",
        "df['center'] = df['center'].apply(path_leaf)\n",
        "df['left'] = df['left'].apply(path_leaf)\n",
        "df['right'] = df['right'].apply(path_leaf)\n",
        "\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "UFpS64rye4-J",
        "outputId": "d6cf92f4-a525-48d4-ba41-6be3439f7e94"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               center                              left  \\\n",
              "0  center_2023_02_13_14_28_29_922.jpg  left_2023_02_13_14_28_29_922.jpg   \n",
              "1  center_2023_02_13_14_28_30_025.jpg  left_2023_02_13_14_28_30_025.jpg   \n",
              "2  center_2023_02_13_14_28_30_127.jpg  left_2023_02_13_14_28_30_127.jpg   \n",
              "3  center_2023_02_13_14_28_30_227.jpg  left_2023_02_13_14_28_30_227.jpg   \n",
              "4  center_2023_02_13_14_28_30_329.jpg  left_2023_02_13_14_28_30_329.jpg   \n",
              "5  center_2023_02_13_14_28_30_430.jpg  left_2023_02_13_14_28_30_430.jpg   \n",
              "6  center_2023_02_13_14_28_30_531.jpg  left_2023_02_13_14_28_30_531.jpg   \n",
              "7  center_2023_02_13_14_28_30_634.jpg  left_2023_02_13_14_28_30_634.jpg   \n",
              "8  center_2023_02_13_14_28_30_740.jpg  left_2023_02_13_14_28_30_740.jpg   \n",
              "9  center_2023_02_13_14_28_30_842.jpg  left_2023_02_13_14_28_30_842.jpg   \n",
              "\n",
              "                               right  steering  throttle  reverse     speed  \n",
              "0  right_2023_02_13_14_28_29_922.jpg  0.0       0.0       0.0      0.000078  \n",
              "1  right_2023_02_13_14_28_30_025.jpg  0.0       0.0       0.0      0.000081  \n",
              "2  right_2023_02_13_14_28_30_127.jpg  0.0       0.0       0.0      0.000079  \n",
              "3  right_2023_02_13_14_28_30_227.jpg  0.0       0.0       0.0      0.000078  \n",
              "4  right_2023_02_13_14_28_30_329.jpg  0.0       0.0       0.0      0.000079  \n",
              "5  right_2023_02_13_14_28_30_430.jpg  0.0       0.0       0.0      0.000079  \n",
              "6  right_2023_02_13_14_28_30_531.jpg  0.0       0.0       0.0      0.000078  \n",
              "7  right_2023_02_13_14_28_30_634.jpg  0.0       0.0       0.0      0.000078  \n",
              "8  right_2023_02_13_14_28_30_740.jpg  0.0       0.0       0.0      0.000081  \n",
              "9  right_2023_02_13_14_28_30_842.jpg  0.0       0.0       0.0      0.000078  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-712fb087-e12b-43e6-ad32-08a1d673a19f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>center</th>\n",
              "      <th>left</th>\n",
              "      <th>right</th>\n",
              "      <th>steering</th>\n",
              "      <th>throttle</th>\n",
              "      <th>reverse</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>center_2023_02_13_14_28_29_922.jpg</td>\n",
              "      <td>left_2023_02_13_14_28_29_922.jpg</td>\n",
              "      <td>right_2023_02_13_14_28_29_922.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>center_2023_02_13_14_28_30_025.jpg</td>\n",
              "      <td>left_2023_02_13_14_28_30_025.jpg</td>\n",
              "      <td>right_2023_02_13_14_28_30_025.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>center_2023_02_13_14_28_30_127.jpg</td>\n",
              "      <td>left_2023_02_13_14_28_30_127.jpg</td>\n",
              "      <td>right_2023_02_13_14_28_30_127.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>center_2023_02_13_14_28_30_227.jpg</td>\n",
              "      <td>left_2023_02_13_14_28_30_227.jpg</td>\n",
              "      <td>right_2023_02_13_14_28_30_227.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>center_2023_02_13_14_28_30_329.jpg</td>\n",
              "      <td>left_2023_02_13_14_28_30_329.jpg</td>\n",
              "      <td>right_2023_02_13_14_28_30_329.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>center_2023_02_13_14_28_30_430.jpg</td>\n",
              "      <td>left_2023_02_13_14_28_30_430.jpg</td>\n",
              "      <td>right_2023_02_13_14_28_30_430.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>center_2023_02_13_14_28_30_531.jpg</td>\n",
              "      <td>left_2023_02_13_14_28_30_531.jpg</td>\n",
              "      <td>right_2023_02_13_14_28_30_531.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>center_2023_02_13_14_28_30_634.jpg</td>\n",
              "      <td>left_2023_02_13_14_28_30_634.jpg</td>\n",
              "      <td>right_2023_02_13_14_28_30_634.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>center_2023_02_13_14_28_30_740.jpg</td>\n",
              "      <td>left_2023_02_13_14_28_30_740.jpg</td>\n",
              "      <td>right_2023_02_13_14_28_30_740.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>center_2023_02_13_14_28_30_842.jpg</td>\n",
              "      <td>left_2023_02_13_14_28_30_842.jpg</td>\n",
              "      <td>right_2023_02_13_14_28_30_842.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000078</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-712fb087-e12b-43e6-ad32-08a1d673a19f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-712fb087-e12b-43e6-ad32-08a1d673a19f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-712fb087-e12b-43e6-ad32-08a1d673a19f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot steering angle of images on histogram visualizing is veru=y important to check irregularities in data\n",
        "\n",
        "num_bins = 25 #(odd for cetral distribution)\n",
        "samples_per_bin = 275\n",
        "hist, bins = np.histogram(df['steering'], num_bins)#(steering values, divide them by no of bins) # returns 2 vals, values of histogram, interval of bins(steering angles)\n",
        "\n",
        "#the center value of the data should be 0 and the distribution of steerng angles should be around it\n",
        "center = (bins[:-1] + bins[1:])*0.5  #(starting at -1 till 0.92) + (starting at -0.92 to 1)(-0.04+0.04 = 0) \n",
        "# by doing the above middle neighbours are added and others are doubled, so finally we have to deivide them by 2 \n",
        "\n",
        "print(center)\n",
        "plt.bar(center, hist, width = 0.05)#(range of vals, vals of histogram, widhth of each bar)\n",
        "\n",
        "# more zero angles as track was more centered, we dont want our model to be more biased to center driving so reduce the dataset by setting max threshold to approx 300\n",
        "plt.plot(np.min(df['steering']),np.max(df['steering']), (samples_per_bin, samples_per_bin))#(min,max , x-samples per bin, y-samples per bin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "r_aVpLBmhU01",
        "outputId": "aa803cee-cf66-4488-d5d4-8b5db0e7c360"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.96 -0.88 -0.8  -0.72 -0.64 -0.56 -0.48 -0.4  -0.32 -0.24 -0.16 -0.08\n",
            "  0.    0.08  0.16  0.24  0.32  0.4   0.48  0.56  0.64  0.72  0.8   0.88\n",
            "  0.96]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3c8ebdbf70>,\n",
              " <matplotlib.lines.Line2D at 0x7f3c8ebdbfd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# remove all samples above the threshold\n",
        "print('total_data:',len(df))\n",
        "remove_list = []\n",
        "for j in range(num_bins): #loop through the bins\n",
        "  list_ = []\n",
        "  for i in range(len(df)): #isolate streering data in a certain bin\n",
        "  # if the steering angle at the index is greater than tthe current bin [j] && steering data if it is smaller than the bin that comes after the current one\n",
        "    if df['steering'][i] >= bins[j] and df['steering'][i] <= bins[j+1]: # condition  for checking  the steering angle\n",
        "  # eg a value of -0.97 -0.96,-0.95 all belong to the same bin\n",
        "      list_.append(i) \n",
        "\n",
        "  list_ = shuffle(list_) #part of outer loop\n",
        "  list_=list_[samples_per_bin:] #(from the limit to above) #isolate the extra part of the list and put it in the empty remove list\n",
        "  # we have to shuffle the list after every interval because if we have 500 instances of left steering angles and our limit is 300 we just cant reject the last 200 because these angles \n",
        "  #are in chronological order and we would lose the angles at the end of the track .They are from start to end hence shuffling is important to get uniform data from start to end.\n",
        "  remove_list.extend(list_)\n",
        "\n",
        "print('removed:',len(remove_list))\n",
        "# now we will drop the data using the indices in this remove list from our actual df\n",
        "df.drop(df.index[remove_list], inplace = True) # inplace = true so that the updated value stays on the same copy\n",
        "print('remaining:',len(df))\n",
        "hist, _ = np.histogram(df['steering'],(num_bins))#(,no of intervals)\n",
        "#plotting\n",
        "plt.bar(center, hist, width = 0.05)\n",
        "plt.plot(np.min(df['steering']),np.max(df['steering']), (samples_per_bin, samples_per_bin))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "ZNbqnV5GiRwb",
        "outputId": "11f3c4d7-90f4-4b2a-a6bd-1a363bb3ccda"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_data: 5672\n",
            "removed: 3876\n",
            "remaining: 1796\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3c8f71d160>,\n",
              " <matplotlib.lines.Line2D at 0x7f3c8f71d1c0>]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# record recovery laps where we make seperate recording of the car constatntly steering from the side to recover\n"
      ],
      "metadata": {
        "id": "xUNrupqelaJt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING AND VALIDATION SPLIT\n",
        " # images as training data an steering angles as lables\n",
        "print(df.iloc[1])\n",
        "def load_image_steering(data_directory,df): \n",
        "   image_path = [] #X\n",
        "   steering = []   #y\n",
        "   for i in range(len(df)):\n",
        "     index_data = df.iloc[i] #iloc allows us to do a selection on the row of data from the df based on the index\n",
        "     center, left, right = index_data[0], index_data[1], index_data[1]\n",
        "     #we are going to now take the center images and place them in the image list with the original path and convert it to an array so that it can be split into training and validation data#\n",
        "     #NOTE that we have to add the full path of the images that are currently shortened\n",
        "     image_path.append(os.path.join (data_directory,center.strip()))  #(join the directory with corresponding image name, .stip eliminates spaces if any in string )\n",
        "     steering.append(float(index_data[3]))\n",
        "   \n",
        "   #conv list to arrays\n",
        "   image_paths = np.asarray(image_path)   \n",
        "   steerings = np.asarray(steering)\n",
        "\n",
        "   return image_paths, steerings\n",
        "\n",
        "image_paths,steerings =  load_image_steering(data_directory,df)\n",
        "\n",
        "#split these in train and validation using a model from sklearn (train_test_split)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5ackWibuFsH",
        "outputId": "5b6798db-1ae8-4544-eff4-393d2f5f18ca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "center      center_2023_02_13_14_28_30_025.jpg\n",
            "left        left_2023_02_13_14_28_30_025.jpg  \n",
            "right       right_2023_02_13_14_28_30_025.jpg \n",
            "steering    0.0                               \n",
            "throttle    0.0                               \n",
            "reverse     0.0                               \n",
            "speed       0.000081                          \n",
            "Name: 1, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(image_paths, steerings, test_size=0.2, random_state=6) #(X,y,split,random seed)\n",
        "print('Training samples : {} \\n Valid samples : {}'.format(len(X_train),len(X_valid)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTQNtCUj3sst",
        "outputId": "da15aa7b-512b-462f-938f-aacec33d419b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples : 1436 \n",
            " Valid samples : 360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot X_train and X_valid using subplots-2 outputs figs and axes 2 histograms one at index  and one at index 2\n",
        "fig, axes = plt.subplots(1,2, figsize=(12,4))#(no of rows,cols,figsize)\n",
        "axes[0].hist(y_train,bins = num_bins, width = 0.05,color = 'blue') #(plotting steering angles)\n",
        "axes[0].set_title('Training set')\n",
        "axes[1].hist(y_valid,bins = num_bins, width = 0.05,color = 'red') #(plotting steering angles)\n",
        "axes[1].set_title('validation set')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "KT1dhjs10_BN",
        "outputId": "69b4d885-a082-448b-e188-1016df3536eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'validation set')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# both follow a general trend center bias seen"
      ],
      "metadata": {
        "id": "5p1BRoZG2_Uv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### PREPROCESSING IMAGES \n",
        "#we have the image paths so we have to now include and read the image from the path to preprocess"
      ],
      "metadata": {
        "id": "qWvhIRbW3Ewx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we dont need to focus on a lot of features in the image as the top part is just scenery and bottom part is just the hood of the car\n",
        "# so lets crop it as we know th image is a 3d array(height,width,channels)# as we want to reduce height we'll keep th other params default\n",
        "#(to use the Nvidia architecture it is suggested to use yuv colorspace for our dataset as opposed to the deafault rgb format or even grayscale img )\n",
        "\n",
        "def img_preprocess(img):\n",
        "  img = mpimg.imread(img) #reading image from path\n",
        "  img = img[60:135,:,:]\n",
        "  cv2.cvtColor(img,cv2.COLOR_RGB2YUV) # yuv 3 channels - y(luminosty/brightness),u,v(chromium components which add colors to the image)\n",
        "  #Gaussian blur for smoothening and reducing noise kernel convolution\n",
        "  img = cv2.GaussianBlur(img, (3,3), 0)\n",
        "  # resize to increase size for faster computation\n",
        "  cv2.resize(img, (200,66)) #(image,size of image)\n",
        "  #normalize(no visual immpact)\n",
        "  img = img/255\n",
        "  return img\n"
      ],
      "metadata": {
        "id": "0aCIfkHy3JFK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comparing original to  image to preprocessed image # define them independently\n",
        "image = image_paths[100]\n",
        "original_image = mpimg.imread(image)\n",
        "preprocessed_image = img_preprocess(image)\n",
        "\n",
        "fig,axs = plt.subplots(1,2,figsize=(15,10))\n",
        "fig.tight_layout\n",
        "axs[0].imshow(original_image)\n",
        "axs[0].set_title('Original Image')\n",
        "axs[1].imshow(preprocessed_image)\n",
        "axs[1].set_title('Preprocessed Image')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "InOdlDCQ-9Pb",
        "outputId": "8b2c24d3-487b-47fc-e307-83ae0b32a9d0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-4f767959da7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# comparing original to  image to preprocessed image # define them independently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moriginal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpreprocessed_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1462\u001b[0m             raise ValueError('Only know how to handle PNG; with Pillow '\n\u001b[1;32m   1463\u001b[0m                              'installed, Matplotlib can handle more images')\n\u001b[0;32m-> 1464\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1465\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_png\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Track_Deep_Learning/center_2023_02_13_14_29_00_924.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing the taining dataset\n",
        "\n",
        "#using map fucntion to iterate through entire array. and for every element it loops though returns a new elements based on fucntion that is executed for each item in the array\n",
        "# this essentially creates a new updated array with the modified items \n",
        "\n",
        "X_train = np.array(list(img_preprocess,X_train))#(fn,array) returns a list then convert it back to array using asarray"
      ],
      "metadata": {
        "id": "_dfRSKNhAAU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Veryfying whether the data is preprocessed or not by taking a random image from the dataset and viewing it"
      ],
      "metadata": {
        "id": "X7hLNJ_ezSmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[random.randint(0, len(X_train) - 1)])#(from 0 to len-1)\n",
        "plt.axis(\"off\")\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "id": "ttHk6_-azaS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### NVIDIA MODEL ARCHITECTURE "
      ],
      "metadata": {
        "id": "zZSKXm0vDGo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nvidia_model(): # cnvolutional != conv2d\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(24, kernel_size=(5,5), strides=(2,2), input_shape=(66,200,3),activation='elu'))\n",
        "  #model.add(convolutional2D(24,5,5, subsamples(strides 2,2), input_shape(66,200,3, actiavation=)))\n",
        "\n",
        "  model.add(Conv2D(36, kernel_size=(5,5), strides=(2,2), activation='elu'))\n",
        "  # 3 more layers with changed attributes remove strides and reduce kernel size towards the end as image size reduces \n",
        "  model.add(Conv2D(48, kernel_size=(5,5), strides=(2,2), activation='elu'))\n",
        "  model.add(Conv2D(64, kernel_size=(3,3), activation='elu'))\n",
        "\n",
        "  model.add(Conv2D(64, kernel_size=(3,3), activation='elu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  #flatten and input to fully connected layers\n",
        "  model.add(Dense(100, activation='elu'))\n",
        "  #Dropout in between DNN to reduce overfitting\n",
        "  #0.5 - 50 percent of randomly selected nodes are turned off \n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "  model.add(Dense(50, activation='elu'))\n",
        "  model.add(Dropout(0.5)) # new dropout for reducing overfitting\n",
        "\n",
        "  model.add(Dense(10, activation ='elu'))\n",
        "  model.add(Dropout(0.5)) # new dropout for reducing overfitting\n",
        "\n",
        "  #last layer with one noode\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  # slow learning rate for efficient learning\n",
        "  optimizer= Adam(1e-3)\n",
        "  # regression model therefore mean square error loss to be calculated (poly reg module)\n",
        "  model.compile(loss='mse', optimizer=optimizer)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "vucQlD0w4ve3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nvidia_model()\n",
        "print(model.summary)"
      ],
      "metadata": {
        "id": "Vw7sK8514vll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train,y_train, epochs =30, validation_data=(X_valid,y_valid), batch_size=100, verbose=1, shuffle=1)"
      ],
      "metadata": {
        "id": "YwE4TaxL4v0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # In training process our epochs are increasing but loss is not going down \n",
        "# # Relu is good for big computations, reliale and quick, but in this case the loss is not converging\n",
        "# # relu can cause somethiing called ddead relu and only feeds 0 to the following nodes \n",
        "# if value is less than 0 if the value is greater than 0 the  that value is retuned.\n",
        "# the gradient of relu in the posive direction is one but in the negative direction is 0\n",
        "# therefore if a node gets an input of negative number it wil return 0 and as gradient at this point is zero the weight will never change as back propogation use gradient value to converge. \n",
        "# # hence the value will not reduce as back propogation will be zero so on so forth\n",
        "#if many relus die this happepns  so use elu\n",
        "#elu same in +ve region to relu but in -ve region will give a negative gradient value"
      ],
      "metadata": {
        "id": "BTIPqBsk4wAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['Training','Validation'])\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')"
      ],
      "metadata": {
        "id": "g2EMA73f4t5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#before applying the model to the simulator we need to save our model"
      ],
      "metadata": {
        "id": "O2gbNKi1IDdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "rrKZ15fxNsvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download model"
      ],
      "metadata": {
        "id": "RioflcxdN0CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "VFYvaJShN2U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('model.h5') # may not work so save a copy in drive and re run it there then try it on google chrome"
      ],
      "metadata": {
        "id": "Qy6XabYYN5bu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}